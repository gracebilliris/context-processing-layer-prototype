{
  "name": "Context Processing Layer",
  "nodes": [
    {
      "parameters": {
        "topic": "context-processing-layer-trigger-topic",
        "groupId": "n8nâ€‘telemetryâ€‘processor",
        "options": {
          "fromBeginning": true,
          "jsonParseMessage": true,
          "parallelProcessing": false,
          "onlyMessage": false
        }
      },
      "type": "n8n-nodes-base.kafkaTrigger",
      "typeVersion": 1.1,
      "position": [
        -1008,
        -304
      ],
      "id": "c16713b1-4a9a-4d63-91ae-73b1878ad791",
      "name": "Kafka Trigger",
      "credentials": {
        "kafka": {
          "id": "6jfMb50m9IHxaOT5",
          "name": "Local"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=The input: {{ $json.toJsonString() }}",
        "options": {
          "systemMessage": "You are the Telemetry Collector Agent in the Context Processing Layer.\n\nYour responsibility is to transform normalized telemetry into enriched contextual metadata.\nYou do not normalize raw telemetry â€” everything you consume is assumed to already meet schema standards.\n\nYour Goals:\n1. Extract and label key entities (agents, tasks, humans, models, systems).\n2. Identify attributes (status, timestamps, event type, metrics).\n3. Detect relationships such as `actor â†’ action â†’ target`, `parent â†’ child span`, `task â†’ agent`.\n4. Compute contextual values when possible:\n   â€¢ duration_ms = end_time - start_time\n   â€¢ severity derived from status, latency, or error codes\n   â€¢ event class (action, error, workflow, communication, coordination)\n\nOutput Required:\nReturn JSON structured as contextual telemetry:\n\n{\n  \"timestamp\": <ISO time>,\n  \"actor\": <entity>,\n  \"target\": <entity or null>,\n  \"job\": <string>,\n  \"severity\": <low|medium|high>,\n  \"duration_ms\": <number|null>,\n  \"relationships\": [...],\n  \"attributes\": {...},\n  \"context_summary\": <1-2 sentence interpretation>,\n  \"confidence\": <0.0 - 1.0>,\n  \"raw\": <full unchanged input>,\n  \"parseError\": false\n}\n\nIf any critical telemetry is missing, set:\n  parseError = true\n  all other values = null\n  raw = original input",
          "maxIterations": 1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        -784,
        -304
      ],
      "id": "29a87c06-73b6-41db-bda8-341f4550e443",
      "name": "Telemetry Collector Agent",
      "alwaysOutputData": false,
      "retryOnFail": false,
      "maxTries": 2
    },
    {
      "parameters": {
        "collection": "telemetry_raw",
        "options": {}
      },
      "type": "n8n-nodes-base.mongoDbTool",
      "typeVersion": 1.2,
      "position": [
        -648,
        -80
      ],
      "id": "96d2cf8d-0f23-4103-8a1a-65245e5baf2c",
      "name": "Find documents in MongoDB",
      "credentials": {
        "mongoDb": {
          "id": "Z7jxTD1dalW8RTbt",
          "name": "telemetry_db mongodb"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        -776,
        -80
      ],
      "id": "69c175de-09b1-47e1-9514-eb33439e23e4",
      "name": "Google Gemini Chat Telemetry Model",
      "credentials": {
        "googlePalmApi": {
          "id": "o10iJinyDP9fgkMP",
          "name": "Google Gemini(PaLM) Api Telemetry"
        }
      }
    },
    {
      "parameters": {
        "operation": "insert",
        "collection": "enriched_telemetry_raw",
        "fields": "timestamp, actor, target, job, severity, duration_ms, relationships, attributes, context_summary, confidence, raw, parseError",
        "options": {}
      },
      "name": "Insert to Enriched Telemetry DB",
      "type": "n8n-nodes-base.mongoDb",
      "typeVersion": 1.2,
      "position": [
        -208,
        -304
      ],
      "id": "e3b4727d-d039-4901-948e-03176df8a463",
      "credentials": {
        "mongoDb": {
          "id": "Z7jxTD1dalW8RTbt",
          "name": "telemetry_db mongodb"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const rawInput = $input.item.json.output;\n\n// 1. Remove ```sparql fences\nlet sparql = rawInput.replace(/```sparql|```/gi, '').trim();\n\n// 2. Ensure required PREFIX declarations exist\nconst prefixes = `\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\nPREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n`;\n\nif (!sparql.toLowerCase().startsWith('prefix')) {\n  sparql = prefixes.trim() + '\\n\\n' + sparql;\n}\n\n// 3. Escape string literals with FULL xsd IRIs\nsparql = sparql.replace(\n  /\"([^\"]*?)\"\\^\\^<http:\\/\\/www\\.w3\\.org\\/2001\\/XMLSchema#(string|dateTime|float)>/g,\n  (_, value, type) => {\n    const escaped = value.replace(/\\\\/g, '\\\\\\\\').replace(/\"/g, '\\\\\"');\n    return `\"${escaped}\"^^xsd:${type}`;\n  }\n);\n\n// 4. (Optional but recommended) normalize boolean & integer literals\nsparql = sparql.replace(\n  /\"true\"\\^\\^xsd:boolean/g,\n  'true^^xsd:boolean'\n);\n\nsparql = sparql.replace(\n  /\"(\\d+)\"\\^\\^xsd:integer/g,\n  '$1^^xsd:integer'\n);\n\nreturn {\n  json: {\n    sparqlQuery: sparql\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1168,
        -304
      ],
      "id": "822a6241-3c8c-4417-91a7-0b4f699ec828",
      "name": "Extract Data for Graph DB"
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Get the raw output safely\nlet raw = item.json.output || null;\n\nlet input;\n\n// If raw exists, remove markdown wrappers and parse JSON\nif (raw) {\n  // Remove ```json ``` wrappers if present\n  raw = raw.replace(/^```json\\s*/i, '').replace(/```$/i, '');\n  try {\n    input = JSON.parse(raw);\n  } catch (error) {\n    input = {};\n  }\n} else {\n  input = {};\n}\n\n// ðŸ”§ FIX: support string OR object actor/target\nconst actorId =\n  typeof input.actor === 'string'\n    ? input.actor\n    : input.actor?.id || null;\n\nconst targetId =\n  typeof input.target === 'string'\n    ? input.target\n    : input.target?.id || null;\n\n// Build the standardized JSON object\nitem.json = {\n  timestamp: input.timestamp\n    ? new Date(input.timestamp).toISOString()\n    : new Date().toISOString(),\n\n  actor: actorId\n    ? {\n        type:\n          typeof input.actor === 'object'\n            ? input.actor?.type || 'agent'\n            : 'agent',\n        id: actorId\n      }\n    : null,\n\n  target: targetId\n    ? {\n        type:\n          typeof input.target === 'object'\n            ? input.target?.type || 'agent'\n            : 'agent',\n        id: targetId\n      }\n    : null,\n\n  job: input.job || null,\n  severity: input.severity || null,\n  duration_ms: input.duration_ms != null ? Number(input.duration_ms) : null,\n\n  relationships: (input.relationships || []).map(r => {\n    if (typeof r === 'string') {\n      const [src, rel, tgt] = r.split(' â†’ ');\n      return { source: src, type: rel, target: tgt };\n    }\n    return r;\n  }),\n\n  attributes: input.attributes || {},\n\n  context_summary: input.context_summary || null,\n  confidence: input.confidence != null ? Number(input.confidence) : 1.0,\n  raw: raw || null,\n  parseError: false\n};\n\nreturn item;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -432,
        -304
      ],
      "id": "24273673-42b0-4ef9-b2b4-d2f147bc2bbf",
      "name": "Extract Data for MongoDB"
    },
    {
      "parameters": {
        "operation": "insert",
        "collection": "raw_ontology",
        "fields": "=ontology, mapping, telemetry",
        "options": {}
      },
      "name": "Insert to Raw Ontology DB",
      "type": "n8n-nodes-base.mongoDb",
      "typeVersion": 1.2,
      "position": [
        592,
        -304
      ],
      "id": "5fc97c8b-38d2-4513-ae70-efa3e787c74e",
      "credentials": {
        "mongoDb": {
          "id": "Z7jxTD1dalW8RTbt",
          "name": "telemetry_db mongodb"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        88,
        -80
      ],
      "id": "17247adf-6767-4584-afb7-fcad3f654c59",
      "name": "Google Gemini Ontology Model",
      "credentials": {
        "googlePalmApi": {
          "id": "kLt8bWK54hsaXd9c",
          "name": "Google Gemini(PaLM) Api Ontology"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "function parseTelemetryOutput(input) {\n  if (!input || typeof input.output !== \"string\") {\n    throw new Error(\"Expected input.output to be a string\");\n  }\n\n  let str = input.output\n    .replace(/^```json\\s*/i, '')\n    .replace(/```$/i, '')\n    .trim();\n\n  // Normalize line breaks safely\n  str = str.replace(/\\r\\n/g, '\\n');\n\n  let obj;\n  try {\n    obj = JSON.parse(str);\n  } catch (err) {\n    throw new Error(\"Top-level JSON parse failed: \" + err.message);\n  }\n\n  function expand(o) {\n    if (typeof o === \"string\") {\n      const s = o.trim();\n      if (\n        (s.startsWith(\"{\") && s.endsWith(\"}\")) ||\n        (s.startsWith(\"[\") && s.endsWith(\"]\"))\n      ) {\n        try {\n          return expand(JSON.parse(s));\n        } catch {\n          return o;\n        }\n      }\n      return o;\n    }\n\n    if (Array.isArray(o)) return o.map(expand);\n\n    if (o && typeof o === \"object\") {\n      for (const k in o) {\n        o[k] = expand(o[k]);\n      }\n    }\n    return o;\n  }\n\n  return expand(obj);\n}\n\nreturn parseTelemetryOutput($json);\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        368,
        -304
      ],
      "id": "ea41a7ab-9329-40c4-bf3c-0dbf06669f59",
      "name": "Extract Data for MongoDB Raw Ontology Collection"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Ontology: {{ $json.ontology.toJsonString() }}, Mappings: {{ $json.mapping.toJsonString() }}, Telemetry: {{ $json.telemetry.toJsonString() }}",
        "options": {
          "systemMessage": "You are the Telemetry Transformation & Graph Import Agent.\n\nYou are a deterministic RDF compiler.\n\nINPUTS:\nâ€¢ A mapping contract\nâ€¢ A raw telemetry payload\n\nCOMPILATION RULES:\n\nâ€¢ TelemetryEvent instances describe WHEN and WHAT happened\nâ€¢ Agents, Humans, Tasks are global entities\nâ€¢ Relationship triples MUST be emitted from telemetry.relationships\nâ€¢ attributes.* NEVER creates relationships\nâ€¢ If a relationship exists in telemetry.relationships, it MUST be emitted\nâ€¢ If a relationship does not exist in mapping, it MUST be ignored\n\nRDF RULES:\n\nâ€¢ Emit only instance triples\nâ€¢ Use fully expanded IRIs\nâ€¢ Enforce datatypes exactly\nâ€¢ Emit a single SPARQL INSERT DATA block\nâ€¢ Never invent schema\nâ€¢ Never infer meaning\n\nFAILURE RULES:\n\nâ€¢ Missing required field â†’ reject record\nâ€¢ Invalid datatype â†’ reject record\nâ€¢ Unknown property â†’ omit silently\n\nOUTPUT:\nA single SPARQL INSERT DATA statement."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        816,
        -304
      ],
      "id": "737c7597-cf6a-4be8-86b1-329ec31e6350",
      "name": "Telemetry Transformation Agent",
      "alwaysOutputData": false,
      "retryOnFail": false
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://host.docker.internal:3030/ontology/update",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/sparql-update",
        "body": "={{$json.sparqlQuery}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1392,
        -400
      ],
      "id": "6fa8d477-15bd-4cdc-b3da-77b8305a035d",
      "name": "Graph Importer to GraphDB"
    },
    {
      "parameters": {
        "operation": "insert",
        "collection": "telemetry_transformation",
        "fields": "={{ $json.sparqlQuery }}",
        "options": {}
      },
      "name": "Insert to Telemetry Transformation DB",
      "type": "n8n-nodes-base.mongoDb",
      "typeVersion": 1.2,
      "position": [
        1392,
        -208
      ],
      "id": "12e2b35d-1e23-4be9-a4df-f5be64c68869",
      "credentials": {
        "mongoDb": {
          "id": "Z7jxTD1dalW8RTbt",
          "name": "telemetry_db mongodb"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Input telemetry metadata:\n{{ $json.toJsonString() }}",
        "options": {
          "systemMessage": "You are the Ontology & Mapping Authority Agent.\n\nYou are the single semantic source of truth for the telemetry knowledge graph.\n\nYour responsibility is to define:\n1) A minimal, fact-oriented OWL ontology\n2) A canonical mapping contract that instantiates telemetry into that ontology\n\nSEMANTIC RULES (ABSOLUTE):\n\nâ€¢ Ontology models FACTS, not telemetry mechanics\nâ€¢ Agents perform tasks (never inverted)\nâ€¢ Humans are associated with tasks (not events)\nâ€¢ TelemetryEvent describes occurrence, not ownership\nâ€¢ Relationships are first-class semantic edges\nâ€¢ No ontology element exists unless it appears in mapping\nâ€¢ No mapping element exists unless defined in ontology\n\nONTOLOGY RULES:\n\nYou MUST:\nâ€¢ Emit OWL ontology in JSON-LD\nâ€¢ Declare only owl:Class, owl:ObjectProperty, owl:DatatypeProperty\nâ€¢ Use correct domain/range semantics\nâ€¢ Never emit individuals\n\nYou MUST NOT:\nâ€¢ Reify relationships as nodes\nâ€¢ Encode process flow\nâ€¢ Encode visualization concerns\n\nMAPPING RULES:\n\nâ€¢ Mapping MUST derive strictly from ontology\nâ€¢ Relationships MUST come from telemetry.relationships when present\nâ€¢ attributes.* is for scalar facts only\nâ€¢ eventClass MUST be minimal (TelemetryEvent or subclass)\nâ€¢ Nested entity creation ONLY when semantically required\n\nOUTPUT FORMAT (ABSOLUTE):\n\n{\n  \"ontology\": { â€¦ },\n  \"mapping\": { â€¦ },\n  \"telemetry\": { â€¦ }\n}\n\nNo commentary.\nNo markdown.\nNo deviation.",
          "maxIterations": 1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        16,
        -304
      ],
      "id": "22d29507-ff15-4772-8edb-0bafe1a69af8",
      "name": "Ontology & Mapping Authority Agent",
      "alwaysOutputData": false,
      "retryOnFail": false,
      "maxTries": null
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// n8n Function Node\nconst item = $json; // single telemetry item\n\nlet actor = null;\nlet target = null;\nlet job = \"context_processing_layer\";\nlet latencyMs = 0;\nlet message = item.message || item._id || null;\nlet severity = item.severity || null;\nlet error_code = item.error_code || null;\nlet data_size_kb = typeof item.data_size_kb === \"number\" ? item.data_size_kb : null;\n\n// Use timestamps if available\nconst now = Date.now();\nconst eventTime = item.timestamp ? new Date(item.timestamp).getTime() : now;\nlatencyMs = Math.max(now - eventTime, 0);\n\n// Attempt to extract actor and target from RDF-like fields\nfor (const key in item) {\n    if (!item[key] || typeof item[key] !== \"string\") continue;\n    const value = item[key];\n\n    // Actor\n    const actorMatch = value.match(/hasActor>\\s*<[^#]+#([^>]+)>|isActorOf>\\s*<[^#]+#([^>]+)>/i);\n    if (actorMatch) actor = actorMatch[1] || actorMatch[2];\n\n    // Target\n    const targetMatch = value.match(/hasTarget>\\s*<[^#]+#([^>]+)>|isTargetOf>\\s*<[^#]+#([^>]+)>/i);\n    if (targetMatch) target = targetMatch[1] || targetMatch[2];\n\n    // Latency override if specified\n    const latencyMatch = value.match(/hasDuration(Ms|Milliseconds)>\\s*\"(\\d+)\"/i);\n    if (latencyMatch) latencyMs = parseInt(latencyMatch[2]);\n\n    // Severity\n    const severityMatch = value.match(/hasSeverity>\\s*(?:<[^#]+#([^>]+)>|\"([^\"]+)\")/i);\n    if (severityMatch) severity = severityMatch[1] || severityMatch[2];\n\n    // Error code\n    const errorCodeMatch = value.match(/hasErrorCode>\\s*(?:<[^#]+#([^>]+)>|\"([^\"]+)\")/i);\n    if (errorCodeMatch) error_code = errorCodeMatch[1] || errorCodeMatch[2];\n\n    // Data size\n    const dataSizeMatch = value.match(/hasDataSize(Kb|Kilobytes)>\\s*\"(\\d+)\"/i);\n    if (dataSizeMatch) data_size_kb = parseInt(dataSizeMatch[2]);\n}\n\n// Fallback: parse actor/target from context summary\nif ((!actor || !target) && item.context_summary) {\n    const summaryMatch = item.context_summary.match(/Agent ['\"]?([^'\"]+)['\"]?.*?with ['\"]?([^'\"\\s]+)['\"]?/ims);\n    if (summaryMatch) {\n        actor = actor || summaryMatch[1];\n        target = target || summaryMatch[2];\n    }\n}\n\n// Transform success if actor and target exist\nconst transformSuccess = actor && target ? 1 : 0;\nconst errorCount = transformSuccess ? 0 : 1;\nconst status = transformSuccess ? \"success\" : \"failed\";\n\n// Return standardized output\nreturn {\n    timestamp: eventTime,\n    ingestTimestamp: now,\n    totalCount: 1,\n    ingestCount: 1,\n    transformSuccess,\n    errorCount,\n    latencyMs,\n    trace_id: item.trace_id || null,\n    job,\n    actor: actor || \"unknown\",\n    target: target || \"unknown\",\n    region: item.region || null,\n    host: item.host || null,\n    message,\n    severity,\n    status,\n    error_code,\n    data_size_kb\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1616,
        -208
      ],
      "id": "0fd1f66a-3bf3-43ea-b783-e80bfe28bb04",
      "name": "(1) Capture Metrics"
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Access the current input item\nconst item = $input.item;\n\n// Extract the output object\nconst data = item.json || {};\n\n// Use ingestTimestamp or fallback to now\nconst ingestTime = data.ingestTimestamp ? new Date(data.ingestTimestamp).getTime() : Date.now();\n\n// Use event timestamp if available, else fallback to ingestTime\nconst eventTime = data.timestamp ? new Date(data.timestamp).getTime() : ingestTime;\n\n// Calculate latency in ms (ingestTime - eventTime)\nconst latencyMs = Math.max(ingestTime - eventTime, 0); // avoid negative\n\n// Convert timestamp to nanoseconds for Loki\nconst ts_ns = String(ingestTime * 1e6);\n\n// Build the Loki push payload\nreturn {\n  streams: [\n    {\n      stream: {\n        job: data.job || \"context_processing_layer\",\n        actor: data.actor || \"unknown\",\n        target: data.target || \"unknown\",\n        region: data.region || \"unknown\",\n        host: data.host || \"unknown\",\n\n        // Metric labels\n        ingestCount: String(data.ingestCount ?? \"0\"),\n        transformSuccess: String(data.transformSuccess ?? \"0\"),\n        totalCount: String(data.totalCount ?? \"0\"),\n        errorCount: String(data.errorCount ?? \"0\"),\n        latencyMs: String(latencyMs)   // <-- dynamically calculated\n      },\n      values: [\n        [ts_ns, data.message || data.id || \"No message\"]\n      ]\n    }\n  ]\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1840,
        -208
      ],
      "id": "286c5063-09ea-40f9-a12b-1efd6d71a662",
      "name": "Formatting for Grafana"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://logs-prod-026.grafana.net/loki/api/v1/push",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json  }}",
        "options": {
          "response": {
            "response": {
              "fullResponse": true
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2064,
        -208
      ],
      "id": "1812dd88-dada-44b7-bbeb-80764a6b0067",
      "name": "Push Grafana Metrics",
      "credentials": {
        "httpBearerAuth": {
          "id": "XxPMszNrbPNCdKEB",
          "name": "Bearer Auth account"
        },
        "httpBasicAuth": {
          "id": "BXE8sqrEF7PkKNmf",
          "name": "BasicAuth"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        888,
        -80
      ],
      "id": "908b7575-2d23-47e8-8310-634a460177f6",
      "name": "Google Gemini Transformation Model",
      "credentials": {
        "googlePalmApi": {
          "id": "hIAX2nYQz6mAucbu",
          "name": "Google Gemini(PaLM) Api Telemetry Transformation Agent"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "Kafka Trigger": {
      "main": [
        [
          {
            "node": "Telemetry Collector Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Find documents in MongoDB": {
      "ai_tool": [
        [
          {
            "node": "Telemetry Collector Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Telemetry Collector Agent": {
      "main": [
        [
          {
            "node": "Extract Data for MongoDB",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Telemetry Model": {
      "ai_languageModel": [
        [
          {
            "node": "Telemetry Collector Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Insert to Enriched Telemetry DB": {
      "main": [
        [
          {
            "node": "Ontology & Mapping Authority Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Data for Graph DB": {
      "main": [
        [
          {
            "node": "Graph Importer to GraphDB",
            "type": "main",
            "index": 0
          },
          {
            "node": "Insert to Telemetry Transformation DB",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Data for MongoDB": {
      "main": [
        [
          {
            "node": "Insert to Enriched Telemetry DB",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Ontology Model": {
      "ai_languageModel": [
        [
          {
            "node": "Ontology & Mapping Authority Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Extract Data for MongoDB Raw Ontology Collection": {
      "main": [
        [
          {
            "node": "Insert to Raw Ontology DB",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Telemetry Transformation Agent": {
      "main": [
        [
          {
            "node": "Extract Data for Graph DB",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Insert to Raw Ontology DB": {
      "main": [
        [
          {
            "node": "Telemetry Transformation Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Graph Importer to GraphDB": {
      "main": [
        []
      ]
    },
    "Insert to Telemetry Transformation DB": {
      "main": [
        [
          {
            "node": "(1) Capture Metrics",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ontology & Mapping Authority Agent": {
      "main": [
        [
          {
            "node": "Extract Data for MongoDB Raw Ontology Collection",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "(1) Capture Metrics": {
      "main": [
        [
          {
            "node": "Formatting for Grafana",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Formatting for Grafana": {
      "main": [
        [
          {
            "node": "Push Grafana Metrics",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Push Grafana Metrics": {
      "main": [
        []
      ]
    },
    "Google Gemini Transformation Model": {
      "ai_languageModel": [
        [
          {
            "node": "Telemetry Transformation Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "e6dd99bd-b130-4c26-8f75-7b2b51d1a841",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "f32d5822a2849cb195e1ab5306933bfaefd5e72c87d29738a06685603d71a039"
  },
  "id": "05494zamiDClnxre",
  "tags": []
}